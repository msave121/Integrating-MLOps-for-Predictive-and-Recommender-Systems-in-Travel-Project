{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d29979",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from features import prepare_X_y\n",
    "from preprocess import prepare_dataset\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "def run_train(users_csv, flights_csv, hotels_csv=None):\n",
    "    print(\"INFO: [MLflow] Starting model training...\")\n",
    "\n",
    "    # --- Connect to your MLflow tracking server ---\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"Voyage Analytics Model\")\n",
    "\n",
    "    # --- Start MLflow run ---\n",
    "    with mlflow.start_run(run_name=\"RandomForest_Training\"):\n",
    "\n",
    "        print(\"INFO: Merging datasets...\")\n",
    "        df = prepare_dataset(users_csv, flights_csv, hotels_csv)\n",
    "\n",
    "        print(\"INFO: Preparing features and target...\")\n",
    "        X, y, preprocessor, num_cols, cat_cols = prepare_X_y(df, target=\"price\")\n",
    "\n",
    "        print(f\"INFO: Using {len(num_cols)} numeric and {len(cat_cols)} categorical columns.\")\n",
    "        print(f\"INFO: Training pipeline on {X.shape[0]} rows, {X.shape[1]} features\")\n",
    "\n",
    "        # --- Model setup ---\n",
    "        params = {\n",
    "            \"n_estimators\": 200,\n",
    "            \"max_depth\": 10,\n",
    "            \"random_state\": 42\n",
    "        }\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"regressor\", RandomForestRegressor(**params))\n",
    "        ])\n",
    "\n",
    "        # --- Log model parameters ---\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # --- Train model ---\n",
    "        pipeline.fit(X, y)\n",
    "\n",
    "        # --- Save columns.json ---\n",
    "        os.makedirs(\"src\", exist_ok=True)\n",
    "        columns_info = {\"num_cols\": num_cols, \"cat_cols\": cat_cols, \"target\": \"price\"}\n",
    "        with open(\"src/columns.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(columns_info, f, indent=2)\n",
    "        print(\"INFO: columns.json saved in src/\")\n",
    "\n",
    "        # --- Save model locally ---\n",
    "        model_dir = \"model/voyage_model/1\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        model_path = os.path.join(model_dir, \"model.pkl\")\n",
    "        joblib.dump(pipeline, model_path)\n",
    "        print(f\"INFO: Model saved at {model_path}\")\n",
    "\n",
    "        # --- Log model to MLflow ---\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=\"VoyagePricePredictor\"\n",
    "        )\n",
    "\n",
    "        print(\"INFO: Model logged to MLflow successfully.\")\n",
    "\n",
    "        # --- Example metric (just for demo) ---\n",
    "        r2 = pipeline.score(X, y)\n",
    "        mlflow.log_metric(\"r2_score\", r2)\n",
    "        print(f\"INFO: Logged metric r2_score = {r2:.4f}\")\n",
    "\n",
    "    print(\"✅ Training complete and tracked with MLflow!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--users\", required=True)\n",
    "    parser.add_argument(\"--flights\", required=True)\n",
    "    parser.add_argument(\"--hotels\", required=False)\n",
    "    args = parser.parse_args()\n",
    "    run_train(args.users, args.flights, args.hotels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790c6b6",
   "metadata": {},
   "source": [
    "Training Script (train_regression.py)\n",
    "\n",
    "Argument Parsing\n",
    "Takes file paths for users, flights, and hotels datasets from the command line, making the script reusable and automation-friendly.\n",
    "\n",
    "MLflow Setup\n",
    "Connects to an MLflow tracking server, sets an experiment, and starts a run to track parameters, metrics, and models.\n",
    "\n",
    "Dataset Preparation\n",
    "Merges users, flights, and hotels data into a single dataset and prepares features (X) and target (y) using preprocessing utilities.\n",
    "\n",
    "Feature Engineering\n",
    "Separates numerical and categorical columns and applies appropriate preprocessing through a Scikit-learn preprocessor.\n",
    "\n",
    "Model Pipeline\n",
    "Uses a Scikit-learn Pipeline combining preprocessing and a RandomForestRegressor, ensuring consistent transformations during training and inference.\n",
    "\n",
    "Model Training & Logging\n",
    "Trains the model, logs hyperparameters and R² score to MLflow, and registers the model in the MLflow Model Registry.\n",
    "\n",
    "Model Persistence\n",
    "Saves the trained pipeline using Joblib and stores feature metadata in columns.json to maintain schema consistency during predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64db516",
   "metadata": {},
   "source": [
    "1. Environment Setup\n",
    "\n",
    "A Python virtual environment is activated to ensure dependency isolation and reproducibility. All required libraries are installed using a requirements.txt file, which includes Flask for API development, Pandas for data handling, Scikit-learn for machine learning, MLflow for experiment tracking, and Joblib for model serialization.\n",
    "\n",
    "This setup ensures that the project can be consistently executed across different systems without dependency conflicts.\n",
    "\n",
    "2. Model Training Pipeline\n",
    "\n",
    "The regression model is trained using a modular training script. The training process begins by merging the users, flights, and hotels datasets into a unified dataset. This consolidated view enables richer feature representation and improved prediction accuracy.\n",
    "\n",
    "Feature preparation is handled through a dedicated preprocessing pipeline that separates numerical and categorical variables. Categorical features are encoded, numerical features are scaled as required, and the target variable is defined as flight price.\n",
    "\n",
    "A Random Forest Regressor is selected for its ability to handle non-linear relationships and mixed feature types. The model is trained using a Scikit-learn pipeline that combines preprocessing and model training into a single, reproducible workflow.\n",
    "\n",
    "3. Experiment Tracking with MLflow\n",
    "\n",
    "MLflow is integrated into the training pipeline to track model parameters, metrics, and artifacts. During training, hyperparameters such as the number of trees and maximum depth are logged, along with performance metrics like the R² score.\n",
    "\n",
    "The trained model is registered in the MLflow Model Registry, enabling version control, comparison across experiments, and smooth promotion to production stages.\n",
    "\n",
    "4. Model Serialization and Metadata Storage\n",
    "\n",
    "After training, the complete pipeline is saved locally using Joblib. Along with the model, a columns.json file is generated to store metadata about the features used during training. This ensures that incoming API requests align exactly with the model’s expected input structure.\n",
    "\n",
    "This design prevents schema mismatches during inference and improves model reliability in production."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
